<?xml version="1.0" encoding="UTF-8"?>

  <!--
    Copyright 2002-2004 The Apache Software Foundation Licensed under the Apache License, Version
    2.0 (the "License"); you may not use this file except in compliance with the License. You may
    obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by
    applicable law or agreed to in writing, software distributed under the License is distributed on
    an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See
    the License for the specific language governing permissions and limitations under the License.
  -->

<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN"
          "http://forrest.apache.org/dtd/document-v20.dtd">

<document>
  <header>
    <title>PigUnit - Pig script testing simplified.</title>
  </header>
  <body>

    <section>
      <title>Overview</title>
      <p>The goal is to provide a simple xUnit framework that enables our Pig scripts to be easily:
      </p>
      <ol>
        <li>
          <p>unit tested</p>
        </li>
        <li>
          <p>regression tested</p>
        </li>
        <li>
          <p>quickly prototyped</p>
        </li>
      </ol>

      <p>No cluster set up is required.</p>
    </section>

    <section>
      <title>PigUnit Example</title>
      <p>Computing top queries, specifying the input data and expected output of the script.</p>
      <p>Java test</p>
      <source>
  @Test
  public void testTop3Queries() {
    String[] args = {
        "n=3",        
        };
    test = new PigTest("top_queries.pig", args);

    String[] input = {
        "yahoo\t10",
        "twitter\t7",
        "facebook\t10",
        "yahoo\t15",
        "facebook\t5",
        ....
    };

    String[] output = {
        "(yahoo,25L)",
        "(facebook,15L)",
        "(twitter,7L)",
    };

    test.assertOutput("data", input, "queries_limit", output);
  }
 </source>
      <p>top_queries.pig</p>
      <source>
data =
    LOAD '$input'
    AS (query:CHARARRAY, count:INT);
     
    ... 
    
queries_sum = 
    FOREACH queries_group 
    GENERATE 
        group AS query, 
        SUM(queries.count) AS count;
        
    ...
            
queries_limit = LIMIT queries_ordered $n;

STORE queries_limit INTO '$output';
</source>

      <p>You just need two jar files in your classpath:</p>
      <ol>
        <li>pig.jar</li>
        <li>pigunit.jar</li>
      </ol>

      <p>
        Many examples are available in the
        <a
          href="http://svn.apache.org/viewvc/pig/trunk/test/org/apache/pig/test/pigunit/TestPigTest.java"
        >PigUnit tests</a>.
      </p>
    </section>

    <section>
      <title>Cluster</title>

      <p>They are 2 main modes:</p>
      <ol>
        <li>LOCAL</li>
        <li>MAPREDUCE</li>
      </ol>

      <section>
        <title>LOCAL</title>
        <p>
          This is using the local mode of Pig.
          It will be used by default.
        </p>

        <p>It will go fast and use your local file system as a HDFS cluster.</p>
      </section>


      <section>
        <title>MAPREDUCE</title>
        <p>This is using a real Hadoop cluster.
          The cluster selected will be the first specified in
          the CLASSPATH (same
          way as the HADOOP_CONF_DIR variable works). You
          can also choose to have
          a test cluster automatically
          starting/stopping or you cab reuse an already
          running cluster.
        </p>

        <section>
          <title>On demand cluster</title>
          <p>
            The default mode is using a local MiniCluster that is started at the very beginning
            and
            shutdown automatically at the end of the test run.
            No setup needed which is really
            helpful. The cluster will contain no data each time it is
            started, but data can be
            copied
            to it as shown in the examples.

            You can select this mode by setting the Java property
            <code>"pigunit.exectype.minicluster"</code>
            to "true".
            </p>
            <p>It can be set in Java or on the command line:</p>
            <ol>
              <li>
                <code>System.setProperty("pigunit.exectype.cluster", "true");</code>
              </li>
              <li>
                <code>-Dpigunit.exectype.cluste=true</code>
              </li>
            </ol>
            <p>
            The
            <code>HADOOP_CONF_DIR</code>
            path will be
            <code>~/pigtest/conf</code>
            and it will be required in the CLASSPATH.
            The path to the log directory is set by the
            Java property
            <code>"hadoop.log.dir"</code>
            (default is "/tmp/pigunit").
          </p>
        </section>

        <section>
          <title>Existing cluster</title>
          <p>
            If
            <code>"pigunit.exectype.cluster"</code>
            property is set, the first xml configuration of an Hadoop cluster found in the
            CLASSPATH
            will be used.

            Notice that PigUnit comes with a standalone MiniCluster that
            can be started
            externally with:
          </p>
          <source>
java -cp .../pig.jar:.../pigunit.jar org.apache.pig.pigunit.MiniClusterRunner
</source>
          <p>This is really useful when doing some prototyping in order to have a test cluster
            ready.</p>
        </section>
      </section>
    </section>

    <section>
      <title>Building</title>
      <p>In order to compile pigunit.jar, go in pig trunk:</p>
      <source>
$pig_trunk ant compile-test
$pig_trunk ant
$pig_trunk ant pigunit-jar   
</source>
    </section>

    <section>
      <title>Troubleshooting</title>
      <p>Common problems</p>
      <section>
        <title>CLASSPATH in MAPREDUCE mode</title>
        <p>When used in MAPREDUCE mode, do not forget the HADOOP_CONF_DIR of your cluster in
          your
          CLASSPATH.</p>
        <p>
          It is
          <code>~/pigtest/conf</code>
          by default
        </p>
        <source>
org.apache.pig.backend.executionengine.ExecException: ERROR 4010: Cannot find hadoop configurations in classpath (neither hadoop-site.xml nor core-site.xml was found in the classpath).If you plan to use local mode, please put -x local option in command line
         </source>
      </section>

      <section>
        <title>UDF jars not found</title>
        <p>This error means that you are missing some jars in your test environment.</p>
        <source>
WARN util.JarManager: Couldn't find the jar for org.apache.pig.piggybank.evaluation.string.LOWER, skip it
         </source>
      </section>

      <section>
        <title>STORING data</title>
        <p>Currently pig is dropping all the STORE/DUMP commands but you can tell PigUnit to
          keep
          them and execute the script.</p>
        <source>
test = new PigTest(PIG_SCRIPT, args);   
test.unoverride("STORE");
test.runScript();
</source>
      </section>

      <section>
        <title>Cache archive</title>
        <p>It works, your test environment will need to have the cache archive options
          specified by
          Java properties or in an additional XML configuration in its
          CLASSPATH.</p>
        <p>If you use a local cluster, you will need to set the required environment
          variables before
          starting it, e.g.</p>
        <source>export LD_LIBRARY_PATH=/home/path/to/lib</source>
      </section>
    </section>

    <section>
      <title>Future</title>
      <p>Improvement and other components based on PigUnit that could be built later.</p>
      <p>We could build on top of PigTest a PigTestCase and PigTestSuite in order to have:</p>
      <ol>
        <li>notion of workspaces for each test</li>
        <li>removing the boiler plate code appearing when there is more than one test
          methods</li>
        <li>standalone utility that reads test configuration and generates a test report...</li>
      </ol>
    </section>
  </body>
</document>
